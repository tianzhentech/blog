<!DOCTYPE html><html lang="zh"><head><meta name="google-site-verification" content="6dKXSVBE3ZyVxHtiFCvc57UwP5MEzcp51X7Wn5okSoE"><link rel="icon" href="/api/images/tianzhen.jpg"><script>document.addEventListener("DOMContentLoaded",function(){var e;768<=(window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth)&&((e=document.createElement("script")).src="/api/js/fireworks.min.js",document.head.appendChild(e),(e=document.createElement("script")).src="/api/js/background.min.js",document.head.appendChild(e),(e=document.createElement("script")).src="/api/js/cursor.min.js",document.head.appendChild(e),(e=document.createElement("canvas")).id="fireworks",e.style.cssText="position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; pointer-events: none; z-index: 32767",document.body.appendChild(e),(e=document.createElement("canvas")).id="background",e.style.cssText="position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; pointer-events: none; z-index: -1",document.body.appendChild(e),(e=document.createElement("div")).id="cursor",document.body.appendChild(e))})</script><meta charset="utf-8"><title>基于PyTorch的手写数字识别（持续补充中......） | Tianzhen</title><meta name="author" content="Tianzhen"><meta name="description" content="My Learning Journey Blog"><meta name="keywords" content="seo优化 javaweb教程 网络技术分享"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><link rel="preconnect" href="https://cdn.staticfile.org"><link rel="preconnect" href="https://twikoo.lt514.com"><link rel="preconnect" href="https://umami.hoshiroko.com"><link rel="preconnect" href="/api"><script src="/api/js/vue.global.prod.min.js"></script><script src="/api/js/anime.min.js"></script><script async src="https://umami.hoshiroko.com/script.js" data-website-id="6c968d09-0bb6-4304-a28c-7944d8474aad"></script><link rel="stylesheet" href="/api/fontawesome/fontawesome6.5.1/css/all.min.css"><link rel="stylesheet" href="/api/css/fonts/fonts.loli.net.min.css"><script>const mixins={}</script><script src="/api/js/highlight.min.js"></script><script src="/api/js/highlightjs-line-numbers.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/11.9.0/styles/github.min.css"><script src="/api/js/lib/highlight.js"></script><script src="https://cdn.staticfile.org/KaTeX/0.16.9/katex.min.js"></script><script src="https://cdn.staticfile.org/KaTeX/0.16.9/contrib/auto-render.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.16.9/katex.min.css"><script src="/js/lib/math.js"></script><script src="/api/js/lib/preview.js"></script><script src="/api/js/twikoo.all.min.js"></script><link rel="stylesheet" href="/api/css/main.css"><style>.flex-container{display:flex;justify-content:center;align-items:center;height:100vh}</style><meta name="generator" content="Hexo 6.3.0"></head><script>var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="o(இ௰இ)怎么就走了！",clearTimeout(st)):(document.title="☆*o(≧▽≦)o*☆欢迎回来！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><body><div id="layout"><transition name="fade"><div id="loading" v-show="loading"><div id="loading-circle"><h2>LOADING</h2><p>加载过慢请开启缓存 浏览器默认开启</p><img src="/api/images/loading.gif"></div></div></transition><div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}"><nav id="desktop-menu"><a class="title" href="/"><span>TIANZHEN</span> </a><a href="/"><i class="fa-solid fa-house fa-fw"></i> <span>&ensp;Home</span> </a><a href="/about"><i class="fa-solid fa-id-card fa-fw"></i> <span>&ensp;About</span> </a><a href="/archives"><i class="fa-solid fa-box-archive fa-fw"></i> <span>&ensp;Archives</span> </a><a href="/categories"><i class="fa-solid fa-bookmark fa-fw"></i> <span>&ensp;Categories</span> </a><a href="/tags"><i class="fa-solid fa-tags fa-fw"></i> <span>&ensp;Tags</span> </a><a target="_blank" rel="noopener" href="https://umami.hoshiroko.com/share/jpoapxn7zGXoKcSv/tianzhentech"><i class="fa-solid fa-chart-column fa-fw"></i> <span>&ensp;Umami</span></a></nav><nav id="mobile-menu"><div class="title" @click="showMenuItems = !showMenuItems"><i class="fa-solid fa-bars fa-fw"></i> <span>&emsp;TIANZHEN</span></div><transition name="slide"><div class="items" v-show="showMenuItems"><a href="/"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-house fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Home</div></div></a><a href="/about"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-id-card fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">About</div></div></a><a href="/archives"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-box-archive fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Archives</div></div></a><a href="/categories"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-bookmark fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Categories</div></div></a><a href="/tags"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-tags fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Tags</div></div></a></div></transition></nav></div><transition name="fade"><div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div></transition><div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'"><div class="article"><div><h1>基于PyTorch的手写数字识别（持续补充中......）</h1></div><div class="info"><span class="date"><span class="icon"><i class="fa-solid fa-calendar fa-fw"></i> </span>2024/5/9 </span><span class="category"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="icon"><i class="fa-solid fa-bookmark fa-fw"></i> </span>机器学习 </a></span><span class="tags"><span class="icon"><i class="fa-solid fa-tags fa-fw"></i> </span><span class="tag"><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="color:#03a9f4">神经网络</a> </span><span class="tag"><a href="/tags/CNN/" style="color:#ffa2c4">CNN</a> </span><span class="tag"><a href="/tags/CUDA/" style="color:#00a596">CUDA</a> </span><span class="tag"><a href="/tags/PyTorch/" style="color:#03a9f4">PyTorch</a></span></span></div><div class="content" v-pre><h1><span id="1-概览">1. 概览</span></h1><h2><span id="11-总体介绍">1.1. 总体介绍</span></h2><p>周志华教授曾表达过这样的思想：快速入门一个学科，不是把一个学科，一本书里面的一个章节研究的非常透彻，而是快速通读全书，大致了解整本书在讲些什么，然后在后续的学习中持续发掘其中的细节，直至慢慢掌握其精髓。以我的理解，就是快速写出它的“hello world”，大概就能一定程度上体会到它在讲些什么。</p><p>而手写数字识别，作为神经网络的入门课，就扮演着“hello world”这样的角色。</p><h2><span id="12-名词解释">1.2. 名词解释</span></h2><blockquote><p>为后续理解作基本的铺垫</p></blockquote><ul><li><p><strong>CNN</strong>，全称卷积神经网络（Convolutional Neural Network），是一种深度学习的算法，特别适合于处理图像数据。CNN在图像识别、语音识别等许多领域都有广泛的应用。</p><p>CNN的主要特点是它可以自动地学习到从原始数据中提取哪些特征是重要的，这是通过训练过程中的权重调整实现的。这与传统的机器学习方法不同，传统的机器学习方法通常需要人工选择和提取特征。</p><p>CNN的基本组成部分包括卷积层、池化层（Pooling Layer）和全连接层（Fully Connected Layer）。卷积层用于从输入数据中提取局部特征，池化层用于降低数据的维度，全连接层则用于将学习到的特征进行最终的分类或回归。</p></li><li><p><strong>MNIST</strong>（Modified National Institute of Standards and Technology database）是一个广泛用于训练各种图像处理系统的大型手写数字数据库。它包含60,000个训练样本和10,000个测试样本，每个样本都是一个28x28像素的灰度图像，代表了0到9的一个数字。</p><p>MNIST数据集是由美国国家标准与技术研究院（NIST）的原始数据集修改和混合而来的。它的目标是作为一个简单的计算机视觉基准数据集，用于科研人员测试和比较不同的机器学习和图像处理算法。</p><p>MNIST数据集的一个重要特点是，它的样本已经进行了预处理，包括中心化、归一化等，这使得它非常适合用于基础的机器学习和深度学习实验。因此，MNIST数据集经常被用作教学和研究的基准数据集，特别是在图像识别和机器学习的初级教学中。</p></li><li><p><strong>CUDA</strong>（Compute Unified Device Architecture）是由NVIDIA公司开发的一种并行计算平台和应用程序接口（API）。它允许开发者使用NVIDIA的图形处理单元（GPU）进行通用计算。</p><p>在过去，GPU主要用于渲染计算机图形，但由于其强大的并行处理能力，现在已经被广泛用于其他计算密集型任务，如科学计算、机器学习和深度学习等。</p><p>CUDA提供了一种相对简单的方式来编写并行代码，使得开发者可以更容易地利用GPU的计算能力。在深度学习中，使用CUDA可以显著加速训练和推理过程，特别是对于需要大量计算的任务，如训练复杂的神经网络模型。</p><p>值得注意的是，虽然CUDA是NVIDIA开发的，但许多深度学习框架（如TensorFlow和PyTorch）都支持使用CUDA，这使得它们可以在NVIDIA的GPU上运行。</p></li><li><p><strong>PyTorch</strong>是一个开源的机器学习库，由Facebook的人工智能研究团队开发。它提供了两个主要功能：</p><ol><li>一个n维数组库，类似于NumPy，但可以在GPU上运行以进行高效的数值计算。</li><li>自动微分系统（用于实现神经网络），支持动态计算图，这使得它在构建和训练复杂的深度学习模型时具有很大的灵活性。</li></ol><p>PyTorch的一个主要特点是其动态计算图系统。在许多其他深度学习库中（如TensorFlow和Theano），计算图在运行前需要被完全定义并编译。相比之下，PyTorch允许你在运行时动态地改变计算图，这使得它更易于理解和调试，也更适合处理变长的输入数据。</p><p>PyTorch还提供了一系列的工具和库，包括用于数据加载和预处理的torchvision库，用于机器学习的torchtext库，以及用于科学计算和高级优化的torch.optim库等。</p><p>PyTorch的设计理念是简洁、灵活和直观，这使得它在研究社区中非常受欢迎，同时也逐渐在工业界得到应用。</p></li><li><p><strong>Kaggle</strong>是一个在线社区，为数据科学家和机器学习工程师提供一个平台，他们可以在这个平台上发现和分享数据集，探索和构建模型，进行数据科学和机器学习竞赛，以及发布和分享他们的工作。</p><p>Kaggle的主要特点包括：</p><ol><li><p><strong>竞赛</strong>：Kaggle最初是作为一个平台开始的，公司和研究者可以在上面发布数据科学竞赛。这些竞赛涵盖了各种问题，从图像分类到文本分析，从预测模型到推荐系统。参与者可以提交他们的解决方案，并在公共排行榜上与其他参与者竞争。许多竞赛还提供现金奖励。</p></li><li><p><strong>数据集</strong>：Kaggle提供了一个平台，用户可以发布、搜索和下载数据集。这些数据集涵盖了各种主题，包括（但不限于）公共卫生、经济学、图像识别、自然语言处理等。</p></li><li><p><strong>Kernels&#x2F;Notebooks</strong>：Kaggle提供了一个在线代码执行环境，称为Kaggle Kernels（现在更名为Kaggle Notebooks）。用户可以在这个环境中编写Python或R代码，进行数据分析和建模，然后分享他们的代码和结果。</p></li><li><p><strong>讨论论坛</strong>：Kaggle社区有一个活跃的讨论论坛，用户可以在这里讨论竞赛、数据集、编程问题，以及数据科学和机器学习的最新趋势。</p></li></ol><p>Kaggle是一个很好的资源，无论你是一个数据科学新手，还是一个有经验的专业人士，都可以在这里学习、分享和发展你的技能。</p></li><li><p><strong>超参数</strong>，在机器学习中，超参数是在开始学习过程之前设置的参数，而不是通过训练得到的参数。换句话说，超参数是模型训练之前由数据科学家或机器学习工程师手动设置的参数。</p><p>超参数可以影响模型的学习过程和模型的性能。例如，对于神经网络，超参数可能包括学习率（决定模型学习的速度），批次大小（每次训练步骤中用于更新模型权重的样本数量），以及训练的轮数（整个数据集通过模型的次数）等。</p><p>另一个例子是支持向量机（SVM）的惩罚参数C和核函数的参数。这些超参数控制模型的复杂性和灵活性。</p><p>选择合适的超参数是机器学习中的一个重要任务，因为不同的超参数可能会导致模型的性能有很大的差异。这个过程通常需要大量的实验和调整，也可以使用一些自动化的方法，如网格搜索、随机搜索或贝叶斯优化等。</p></li><li><p><strong>batch</strong>，在机器学习和深度学习中，”batch”是指用于一次模型更新的数据集的子集。批处理大小（batch size）是一个超参数，定义了每次迭代（或更新）中用于计算梯度的样本数量。</p><p>例如，假设你有一个包含1000个样本的训练集，如果你设置批处理大小为100，那么你的模型将在每个训练周期（epoch）中进行10次更新，每次更新使用100个样本。</p><p>批处理的主要优点是：</p><ol><li><p><strong>计算效率</strong>：使用批处理可以利用并行处理能力，比如GPU，从而提高计算效率。</p></li><li><p><strong>稳定的梯度估计</strong>：使用更大的批处理可以得到更稳定（但可能不是更准确）的梯度估计。</p></li><li><p><strong>内存使用</strong>：对于大型数据集，可能无法一次性将所有数据加载到内存中，批处理可以有效地管理内存使用。</p></li></ol><p>然而，选择批处理大小也是一个权衡。较小的批处理可能会导致更频繁的更新，可能会导致训练过程更快地收敛，但也可能导致梯度估计的噪声更大。另一方面，较大的批处理可能会导致更稳定的梯度估计，但可能需要更多的内存，并且可能需要更多的训练周期才能收敛。</p></li><li><p><strong>epoch</strong>，在机器学习和深度学习中，”epoch”是指整个训练集通过模型一次的过程。换句话说，一个epoch就是模型看过训练集中的每一个样本一次。</p><p>例如，如果你有一个包含1000个样本的训练集，那么一个epoch就是模型对这1000个样本进行一次前向传播和一次反向传播。</p><p>在训练深度学习模型时，通常需要进行多个epoch，因为一次通过所有的训练数据可能不足以让模型学习到数据中的所有模式。通过多次迭代训练数据，模型可以更好地学习和适应数据。</p><p>需要注意的是，epoch的数量也是一个超参数，需要根据具体的任务和数据来设定。太少的epoch可能会导致模型欠拟合，而太多的epoch可能会导致模型过拟合。</p></li><li><p><strong>损失函数</strong>（也被称为代价函数或误差函数）是一个用于衡量机器学习模型预测结果与真实值之间差距的函数。换句话说，它度量了模型的预测错误程度。在训练过程中，我们的目标是最小化这个损失函数。</p><p>损失函数的选择取决于你正在解决的具体问题。例如，对于回归问题（预测一个连续的输出），常见的损失函数是均方误差（Mean Squared Error，MSE），它计算的是模型预测值和真实值之间差值的平方的平均值。对于分类问题（预测一个离散的输出），常见的损失函数是交叉熵损失（Cross-Entropy Loss），它度量的是模型预测的概率分布与真实的概率分布之间的差距。</p><p>损失函数是机器学习中的一个核心概念，因为它定义了我们的优化目标。通过优化算法（如梯度下降），我们可以调整模型的参数以最小化损失函数，从而提高模型的预测性能。</p></li><li><p><strong>反向传播</strong>（Backpropagation）是一种在神经网络中用于训练模型的关键算法。它的主要目标是通过有效地计算梯度来优化损失函数，这个梯度是损失函数相对于模型权重的偏导数。</p><p>反向传播的过程可以分为两个主要步骤：</p><ol><li><p><strong>前向传播</strong>：在这个阶段，输入数据通过网络向前传播，通过每一层的神经元和连接权重，直到生成输出。然后，这个输出与期望的输出（标签）进行比较，计算出损失函数的值。</p></li><li><p><strong>反向传播</strong>：在这个阶段，算法从输出层开始，向后通过网络，计算损失函数相对于每个权重的偏导数（即梯度）。这个过程是通过链式法则（Chain Rule）来完成的，链式法则是微积分中的一个基本原则。</p></li></ol><p>这些梯度然后被用于更新网络的权重，通常是通过一种叫做梯度下降的优化算法。这个过程在整个训练数据集上重复多次（也就是多个”epoch”），直到模型的性能达到满意的水平或者不再显著提高。</p><p>反向传播是深度学习中的一个核心算法，使得训练深度神经网络成为可能。</p></li><li><p><strong>激活函数</strong>在神经网络中起着非常重要的作用。它们被应用于神经元的输出上，以引入非线性因素，使得神经网络能够学习并执行更复杂的任务。</p><p>如果没有激活函数，无论神经网络有多少层，它都只能表示线性变换，这大大限制了网络的表达能力。通过引入非线性激活函数，神经网络可以学习并表示更复杂的模式。</p><p>以下是一些常见的激活函数：</p><ol><li><strong>Sigmoid函数</strong>：Sigmoid函数可以将任何值转换为0到1之间的值，使其可以用于输出层，以表示概率。但是，Sigmoid函数在输入值的绝对值很大时，梯度接近于0，这可能导致梯度消失问题。</li></ol><p><img loading="lazy" src="/../images/image-20240509211312083.png" alt="image-20240509211312083"></p><ol start="2"><li><strong>ReLU（Rectified Linear Unit）函数</strong>：ReLU函数在输入值为负时输出0，在输入值为正时输出输入值本身。ReLU函数简单且计算效率高，但是在输入值为负时，梯度为0，可能导致神经元”死亡”。</li></ol><p><img loading="lazy" src="/../images/image-20240509211350318.png" alt="image-20240509211350318"></p><ol start="3"><li><strong>Tanh函数</strong>：Tanh函数可以将任何值转换为-1到1之间的值，比Sigmoid函数的输出范围更广。但是，Tanh函数也存在梯度消失的问题。</li></ol><p><img loading="lazy" src="/../images/image-20240509211432202.png" alt="image-20240509211432202"></p><ol start="4"><li><strong>Leaky ReLU函数</strong>：为了解决ReLU函数的”死亡”神经元问题，Leaky ReLU在输入值为负时，会有一个小的正斜率。</li></ol><p><img loading="lazy" src="/../images/image-20240509211609072.png" alt="image-20240509211609072"></p><ol start="5"><li><strong>Softmax函数</strong>：Softmax函数可以将一组值转换为概率分布，常用于多分类问题的输出层。</li></ol><p>选择哪种激活函数取决于具体的应用和网络结构。</p></li></ul><h1><span id="2-搭建cuda">2. 搭建CUDA</span></h1><blockquote><p>虽然cpu也可以训练，但是有gpu不用白不用，效率还更高</p></blockquote><h1><span id="3-原理">3. 原理</span></h1><h1><span id="4-编写模型">4. 编写模型</span></h1><h1><span id="5-优化">5. 优化</span></h1><h1><span id="6-总结">6. 总结</span></h1></div><div id="comment"><div id="twikoo-container"></div></div></div><footer id="footer"><div id="footer-wrap"><div>&copy; 2023 - 2024 Tianzhen <span id="footer-icon"><i class="fa-solid fa-font-awesome fa-fw"></i> </span>&commat;Tianzhen</div><div>Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp; <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a></div><div><a href="https://icp.gov.moe/?keyword=20236514" target="_blank">萌ICP备20236514号</a> <a target="_blank" rel="noopener" href="https://beian.miit.gov.cn">豫ICP备2023040339号</a></div></div><div><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("11/07/2023 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="本站已运行 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}setInterval("createtime()",250)</script></div></footer></div><transition name="fade"><div id="preview" ref="preview" v-show="previewShow"><img id="preview-content" ref="previewContent"></div></transition></div><script src="/api/js/main.js"></script><script>twikoo.init({el:"#twikoo-container",envId:"https://twikoo.lt514.com",region:"",path:location.pathname,lang:"zh"})</script><p style="text-align:center;margin:0" id="saintwei"></p><script>var saintwei=function(r){var i="気：",n=["现在开始天晴了","天空比大海还要深，是个未知的世界","天气因你逆转，世界因你天晴","能遇见你真是太好了","不管晴天还是雨天，我只是想和你相遇","我只是想再一次的见到她啊","是你让我找到了存在的意义","无论你在哪里，我一定拼尽全力去见你","拜托了，我们就这样一直在一起","只是天空的样子，就能改变人们的心情","天空上是另一个世界，自古如此","我从来不知道，渴望蓝天的人居然有那么多","天气真的是很不可思议，光只是天空的模样就让人感动不已","这是一个只有我和她知道，关于这世界的秘密","100%的晴天女孩","在充满暴风雨的世界，一起勇敢地爱下去","那年夏天，在那个天空之上的我们，把这个世界的样貌，彻底的改变了","天空比大海还要深，是个未知的世界","重要的人，想见的人，无论晴雨，不管多远，都一定要去见你","晴天里有阳光，阳光总是充满温馨，相信有这么多朋友的厚爱和鼓励，晴天会永远阳光灿烂","天晴得像一张蓝纸，几片薄薄的白云，像被阳光晒化了似的，随风缓缓浮游着","天空澄碧，纤云不染，远山含黛，和风送暖","浅蓝色的天幕，像一幅洁净的丝绒，镶着黄色的金边","一场飘洒的雨后，阳光带着清醒的空气飞来，试问是哪位仙子的生日，阳光如此美丽","晴天的午后，夏日的阳光如水般音符一样灿烂的流动，湿澈了不同的妩媚的忧伤","天那么蓝，连一丝浮絮都没有，像被过滤了一切杂色，瑰丽地熠熠发光","神明啊!求你!求你!求你!让我再见她一次","比起晴空，我更需要阳菜，天气什么的，就这样疯狂下去也可以"].map(function(t){return t}),l=["rgb(110,64,170)","rgb(150,61,179)","rgb(191,60,175)","rgb(228,65,157)","rgb(254,75,131)","rgb(255,94,99)","rgb(255,120,71)","rgb(251,150,51)","rgb(226,183,47)","rgb(198,214,60)","rgb(175,240,91)","rgb(127,246,88)","rgb(82,246,103)","rgb(48,239,130)","rgb(29,223,163)","rgb(26,199,194)","rgb(35,171,216)","rgb(54,140,225)","rgb(76,110,219)","rgb(96,84,200)"],a={text:"",prefixP:-5,skillI:0,skillP:0,direction:"forward",delay:2,step:1};!function t(){var e=n[a.skillI];a.step?a.step--:(a.step=1,a.prefixP<i.length?(0<=a.prefixP&&(a.text+=i[a.prefixP]),a.prefixP++):"forward"===a.direction?a.skillP<e.length?(a.text+=e[a.skillP],a.skillP++):a.delay?a.delay--:(a.direction="backward",a.delay=2):0<a.skillP?(a.text=a.text.slice(0,-1),a.skillP--):(a.skillI=(a.skillI+1)%n.length,a.direction="forward")),r.textContent=a.text,r.appendChild(function(t){for(var e=document.createDocumentFragment(),r=0;r<t;r++){var i=document.createElement("span");i.textContent=String.fromCharCode(94*Math.random()+33),i.style.color=l[Math.floor(Math.random()*l.length)],e.appendChild(i)}return e}(a.prefixP<i.length?Math.min(5,5+a.prefixP):Math.min(5,e.length-a.skillP))),setTimeout(t,75)}()};saintwei(document.getElementById("saintwei"))</script></body></html>