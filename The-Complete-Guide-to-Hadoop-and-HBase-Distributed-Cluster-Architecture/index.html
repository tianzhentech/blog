<!DOCTYPE html><html lang="zh"><head><meta name="google-site-verification" content="6dKXSVBE3ZyVxHtiFCvc57UwP5MEzcp51X7Wn5okSoE"><link rel="icon" href="/api/images/tianzhen.jpg"><script>document.addEventListener("DOMContentLoaded",function(){var e;768<=(window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth)&&((e=document.createElement("script")).src="/api/js/fireworks.min.js",document.head.appendChild(e),(e=document.createElement("script")).src="/api/js/background.min.js",document.head.appendChild(e),(e=document.createElement("script")).src="/api/js/cursor.min.js",document.head.appendChild(e),(e=document.createElement("canvas")).id="fireworks",e.style.cssText="position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; pointer-events: none; z-index: 32767",document.body.appendChild(e),(e=document.createElement("canvas")).id="background",e.style.cssText="position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; pointer-events: none; z-index: -1",document.body.appendChild(e),(e=document.createElement("div")).id="cursor",document.body.appendChild(e))})</script><meta charset="utf-8"><title>搭建一主两从Hadoop集群并部署HBase | Tianzhen</title><meta name="author" content="Tianzhen"><meta name="description" content="My Learning Journey Blog"><meta name="keywords" content="seo优化 javaweb教程 网络技术分享"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><link rel="preconnect" href="https://cdn.staticfile.org"><link rel="preconnect" href="https://twikoo.lt514.com"><link rel="preconnect" href="https://umami.hoshiroko.com"><link rel="preconnect" href="/api"><script src="/api/js/vue.global.prod.min.js"></script><script src="/api/js/anime.min.js"></script><script async src="https://umami.hoshiroko.com/script.js" data-website-id="6c968d09-0bb6-4304-a28c-7944d8474aad"></script><link rel="stylesheet" href="/api/fontawesome/fontawesome6.5.1/css/all.min.css"><link rel="stylesheet" href="/api/css/fonts/fonts.loli.net.min.css"><script>const mixins={}</script><script src="/api/js/highlight.min.js"></script><script src="/api/js/highlightjs-line-numbers.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/11.9.0/styles/github.min.css"><script src="/api/js/lib/highlight.js"></script><script src="https://cdn.staticfile.org/KaTeX/0.16.9/katex.min.js"></script><script src="https://cdn.staticfile.org/KaTeX/0.16.9/contrib/auto-render.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.16.9/katex.min.css"><script src="/api/js/lib/math.js"></script><script src="/api/js/lib/preview.js"></script><script src="/api/js/twikoo.all.min.js"></script><link rel="stylesheet" href="/api/css/main.css"><style>.flex-container{display:flex;justify-content:center;align-items:center;height:100vh}</style><meta name="generator" content="Hexo 6.3.0"></head><script>var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="o(இ௰இ)怎么就走了！",clearTimeout(st)):(document.title="☆*o(≧▽≦)o*☆欢迎回来！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><body><div id="layout"><transition name="fade"><div id="loading" v-show="loading"><div id="loading-circle"><h2>LOADING</h2><p>加载过慢请开启缓存 浏览器默认开启</p><img src="/api/images/loading.gif"></div></div></transition><div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}"><nav id="desktop-menu"><a class="title" href="/"><span>TIANZHEN</span> </a><a href="/"><i class="fa-solid fa-house fa-fw"></i> <span>&ensp;Home</span> </a><a href="/about"><i class="fa-solid fa-id-card fa-fw"></i> <span>&ensp;About</span> </a><a href="/archives"><i class="fa-solid fa-box-archive fa-fw"></i> <span>&ensp;Archives</span> </a><a href="/categories"><i class="fa-solid fa-bookmark fa-fw"></i> <span>&ensp;Categories</span> </a><a href="/tags"><i class="fa-solid fa-tags fa-fw"></i> <span>&ensp;Tags</span> </a><a target="_blank" rel="noopener" href="https://umami.hoshiroko.com/share/jpoapxn7zGXoKcSv/tianzhentech"><i class="fa-solid fa-chart-column fa-fw"></i> <span>&ensp;Umami</span></a></nav><nav id="mobile-menu"><div class="title" @click="showMenuItems = !showMenuItems"><i class="fa-solid fa-bars fa-fw"></i> <span>&emsp;TIANZHEN</span></div><transition name="slide"><div class="items" v-show="showMenuItems"><a href="/"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-house fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Home</div></div></a><a href="/about"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-id-card fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">About</div></div></a><a href="/archives"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-box-archive fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Archives</div></div></a><a href="/categories"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-bookmark fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Categories</div></div></a><a href="/tags"><div class="item"><div style="min-width:20px;max-width:50px;width:10%"><i class="fa-solid fa-tags fa-fw"></i></div><div style="min-width:100px;max-width:150%;width:20%">Tags</div></div></a></div></transition></nav></div><transition name="fade"><div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div></transition><div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'"><div class="article"><div><h1>搭建一主两从Hadoop集群并部署HBase</h1></div><div class="info"><span class="date"><span class="icon"><i class="fa-solid fa-calendar fa-fw"></i> </span>2024/1/26 </span><span class="category"><a href="/categories/%E4%B8%AA%E4%BA%BA%E7%BA%AA%E5%BD%95/"><span class="icon"><i class="fa-solid fa-bookmark fa-fw"></i> </span>个人纪录 </a></span><span class="tags"><span class="icon"><i class="fa-solid fa-tags fa-fw"></i> </span><span class="tag"><a href="/tags/Hadoop/" style="color:#00a596">Hadoop</a> </span><span class="tag"><a href="/tags/HBase/" style="color:#ff7d73">HBase</a></span></span></div><div class="content" v-pre><h1><span id="目录">目录</span></h1><ul><li><a href="#1-%E8%AE%A4%E8%AF%86hadoop%E5%92%8Chbase">1. 认识Hadoop和Hbase</a><ul><li><a href="#11-hadoop%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D">1.1 hadoop简单介绍</a></li><li><a href="#12-hadoop%E6%9E%B6%E6%9E%84">1.2 Hadoop架构</a></li><li><a href="#13-hadoop%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C">1.3 Hadoop如何工作？</a></li><li><a href="#14-hadoop%E7%9A%84%E4%BC%98%E7%82%B9">1.4 Hadoop的优点</a></li><li><a href="#15-hbase%E4%BB%8B%E7%BB%8D">1.5 HBase介绍</a></li><li><a href="#16-hbase%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84">1.6 HBase体系架构</a></li></ul></li><li><a href="#2-%E5%AE%89%E8%A3%85%E6%90%AD%E5%BB%BAhadoop">2. 安装搭建hadoop</a><ul><li><a href="#21-%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E">2.1 配置说明</a></li><li><a href="#22-%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87">2.2 安装前准备</a><ul><li><a href="#221-%E6%9C%BA%E5%99%A8%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E">2.2.1 机器配置说明</a></li><li><a href="#222-%E5%85%B3%E9%97%ADselinux-%E9%98%B2%E7%81%AB%E5%A2%99">2.2.2 关闭selinux、防火墙</a></li><li><a href="#223-%E5%87%86%E5%A4%87%E7%94%A8%E6%88%B7">2.2.3 准备用户</a></li><li><a href="#224-%E4%BF%AE%E6%94%B9hosts%E6%96%87%E4%BB%B6%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90">2.2.4 修改hosts文件，域名解析</a></li><li><a href="#225-%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4">2.2.5 同步时间</a></li><li><a href="#226-ssh%E4%BA%92%E4%BF%A1%E9%85%8D%E7%BD%AE">2.2.6 ssh互信配置</a></li></ul></li><li><a href="#23-%E9%85%8D%E7%BD%AEjdk">2.3 配置jdk</a></li><li><a href="#24-%E5%AE%89%E8%A3%85hadoop">2.4 安装Hadoop</a></li></ul></li><li><a href="#3-%E9%85%8D%E7%BD%AE%E5%90%AF%E5%8A%A8hadoop">3. 配置启动hadoop</a><ul><li><a href="#31-hadoop-envsh-%E9%85%8D%E7%BD%AEhadoop%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">3.1 hadoop-env.sh 配置hadoop环境变量</a></li><li><a href="#32-core-sitexml-%E9%85%8D%E7%BD%AEhdfs">3.2 core-site.xml 配置HDFS</a></li><li><a href="#33-hdfs-sitexml-%E9%85%8D%E7%BD%AEnamenode">3.3 hdfs-site.xml 配置namenode</a></li><li><a href="#34-mapred-sitexml-%E9%85%8D%E7%BD%AE%E6%A1%86%E6%9E%B6">3.4 mapred-site.xml 配置框架</a></li><li><a href="#35-yarn-sitexml-%E9%85%8D%E7%BD%AEresourcemanager">3.5 yarn-site.xml 配置resourcemanager</a></li><li><a href="#36-%E9%85%8D%E7%BD%AEmasters-slaves">3.6 配置masters &amp; slaves</a></li><li><a href="#37-%E5%90%AF%E5%8A%A8%E5%89%8D%E5%87%86%E5%A4%87">3.7 启动前准备</a><ul><li><a href="#371-%E5%87%86%E5%A4%87%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC">3.7.1 准备启动脚本</a></li><li><a href="#372-%E6%8E%88%E6%9D%83">3.7.2 授权</a></li><li><a href="#373-%E9%85%8D%E7%BD%AEhadoop%E5%91%BD%E4%BB%A4%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">3.7.3 配置hadoop命令环境变量</a></li><li><a href="#374-%E9%9B%86%E7%BE%A4%E5%88%9D%E5%A7%8B%E5%8C%96">3.7.4 集群初始化</a></li></ul></li><li><a href="#38-%E5%90%AF%E5%8A%A8hadoop%E9%9B%86%E7%BE%A4">3.8 启动Hadoop集群</a><ul><li><a href="#381-%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%AF%E5%8A%A8%E5%89%8D%E9%9C%80%E8%A6%81%E6%A0%BC%E5%BC%8F%E5%8C%96%E9%9B%86%E7%BE%A4%E6%89%80%E6%9C%89%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%BD%E9%9C%80%E8%A6%81">3.8.1 第一次启动前需要格式化，集群所有服务器都需要</a></li><li><a href="#382-%E5%90%AF%E5%8A%A8%E5%B9%B6%E9%AA%8C%E8%AF%81%E9%9B%86%E7%BE%A4">3.8.2 启动并验证集群</a><ul><li><a href="#1%E5%90%AF%E5%8A%A8namenode-datanode">（1）启动namenode、datanode</a></li><li><a href="#2%E5%90%AF%E5%8A%A8yarn">（2）启动YARN</a></li></ul></li><li><a href="#39-%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F">3.9 集群启动成功</a></li></ul></li></ul></li><li><a href="#4-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEhbase">4. 安装配置Hbase</a><ul><li><a href="#41-%E5%AE%89%E8%A3%85hbase">4.1 安装HBase</a></li><li><a href="#42-%E9%85%8D%E7%BD%AEhbase">4.2 配置HBase</a><ul><li><a href="#421-hbase-envsh-%E9%85%8D%E7%BD%AEhbase%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">4.2.1 hbase-env.sh 配置hbase环境变量</a></li><li><a href="#422-hbase-sitexml-%E9%85%8D%E7%BD%AEhbase">4.2.2 hbase-site.xml 配置hbase</a></li><li><a href="#423-%E6%8C%87%E5%AE%9A%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9">4.2.3 指定集群节点</a></li></ul></li></ul></li><li><a href="#5-%E5%90%AF%E5%8A%A8hbase%E9%9B%86%E7%BE%A4">5. 启动Hbase集群</a><ul><li><a href="#51-%E9%85%8D%E7%BD%AEhbase%E5%91%BD%E4%BB%A4%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">5.1 配置hbase命令环境变量</a></li><li><a href="#52-%E5%90%AF%E5%8A%A8%E5%89%8D%E5%87%86%E5%A4%87">5.2 启动前准备</a></li><li><a href="#53-%E5%90%AF%E5%8A%A8hbase">5.3 启动hbase</a></li><li><a href="#54-%E9%A1%B5%E9%9D%A2%E6%9F%A5%E7%9C%8Bhbase%E7%8A%B6%E6%80%81">5.4 页面查看hbase状态</a></li></ul></li><li><a href="#6-%E5%90%8E%E7%BB%AD%E5%8F%8A%E5%85%B6%E6%80%BB%E7%BB%93">6. 后续及其总结</a></li></ul><h1><span id="1-认识hadoop和hbase">1. 认识Hadoop和Hbase</span></h1><h2><span id="11-hadoop简单介绍">1.1 hadoop简单介绍</span></h2><p>Hadoop是一个使用<strong>java</strong>编写的<strong>Apache开放源代码框架</strong>，它允许使用简单的编程模型跨大型计算机的大型数据集进行<strong>分布式处理</strong>。Hadoop框架工作的应用程序可以在跨计算机群集提供分布式存储和计算的环境中工作。Hadoop旨在<strong>从单一服务器扩展到数千台机器，每台机器都提供本地计算和存储。</strong></p><h2><span id="12-hadoop架构">1.2 Hadoop架构</span></h2><p>Hadoop框架包括以下四个模块：</p><ul><li><strong>Hadoop Common</strong>：这些是其他Hadoop模块所需的<strong>Java库和实用程序</strong>。这些库提供文件系统和操作系统级抽象，并包含启动Hadoop所需的必要Java文件和脚本。</li><li><strong>Hadoop YARN</strong>：这是<strong>作业调度和集群资源管理</strong>的<strong>框架</strong>。</li><li><strong>Hadoop分布式文件系统（HDFS）</strong>：提供对应用程序数据的高吞吐量访问的<strong>分布式文件系统。</strong></li><li><strong>Hadoop MapReduce</strong>： 这是基于YARN的大型数据集<strong>并行处理</strong>系统。</li></ul><p>我们可以使用下图来描述Hadoop框架中可用的这四个组件。</p><p><img loading="lazy" src="/../images/1216496-20190308161357274-1215235226.png" alt="img"></p><p>自2012年以来，术语“Hadoop”通常不仅指向上述基本模块，而且还指向可以安装在Hadoop之上或之外的其他软件包，例如Apache Pig，Apache Hive，Apache HBase，Apache火花等。</p><h2><span id="13-hadoop如何工作">1.3 Hadoop如何工作？</span></h2><p><strong>（1）阶段1</strong></p><p>　　用户&#x2F;应用程序可以通过指定以下项目向Hadoop（hadoop作业客户端）提交所需的进程：</p><ul><li>分布式文件系统中输入和输出文件的位置。</li><li>java类以jar文件的形式包含了map和reduce功能的实现。</li><li>通过设置作业特定的不同参数来进行作业配置。</li></ul><p><strong>（2）阶段2</strong></p><p>　　然后，Hadoop作业客户端将作业（jar &#x2F;可执行文件等）和配置提交给JobTracker，JobTracker负责将软件&#x2F;配置分发到从站，调度任务和监视它们，向作业客户端提供状态和诊断信息。</p><p><strong>（3）阶段3</strong></p><p>　　不同节点上的TaskTrackers根据MapReduce实现执行任务，并将reduce函数的输出存储到文件系统的输出文件中。</p><h2><span id="14-hadoop的优点">1.4 Hadoop的优点</span></h2><ul><li>Hadoop框架允许用户快速编写和测试分布式系统。它是<strong>高效的</strong>，它自动分配数据并在机器上工作，反过来利用CPU核心的底层并行性。</li><li>Hadoop<strong>不依赖硬件提供容错和高可用性（FTHA）</strong>，而是Hadoop库本身被设计为检测和处理应用层的故障。</li><li>服务器可以动态添加或从集群中删除，Hadoop继续运行而不会中断。</li><li>Hadoop的另一大优点是，除了是开放源码，它是<strong>所有平台兼容</strong>的，因为它是基于Java的。</li></ul><h2><span id="15-hbase介绍">1.5 HBase介绍</span></h2><p>Hbase全称为<strong>Hadoop Database</strong>，即hbase是hadoop的数据库，是<strong>一个分布式的存储系统</strong>。Hbase<strong>利用Hadoop的HDFS作为其文件存储系统</strong>，<strong>利用Hadoop的MapReduce来处理Hbase中的海量数据</strong>。<strong>利用zookeeper作为其协调工具</strong>。</p><h2><span id="16-hbase体系架构">1.6 HBase体系架构</span></h2><p><img loading="lazy" src="/../images/1216496-20190308161447939-1022292448.png" alt="img"></p><p><strong>Client</strong></p><ul><li>包含访问HBase的接口并维护cache来加快对HBase的访问</li></ul><p><strong>Zookeeper</strong></p><ul><li>保证任何时候，集群中只有一个master</li><li>存贮所有Region的寻址入口。</li><li>实时监控Region server的上线和下线信息。并实时通知Master</li><li>存储HBase的schema和table元数据</li></ul><p><strong>Master</strong></p><ul><li>为Region server分配region</li><li>负责Region server的负载均衡</li><li>发现失效的Region server并重新分配其上的region</li><li>管理用户对table的增删改操作</li></ul><p><strong>RegionServer</strong></p><ul><li>Region server维护region，处理对这些region的IO请求</li><li>Region server负责切分在运行过程中变得过大的region</li></ul><p>　</p><p><strong>HLog(WAL log)</strong></p><ul><li>HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是 HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和 region名字外，同时还包括sequence number和timestamp，timestamp是” 写入时间”，sequence number的起始值为0，或者是最近一次存入文件系 统中sequence number。</li><li>HLog SequeceFile的Value是HBase的KeyValue对象，即对应HFile中的 KeyValue</li></ul><p><strong>Region</strong></p><ul><li>HBase自动把表水平划分成多个区域(region)，每个region会保存一个表 里面某段连续的数据；每个表一开始只有一个region，随着数据不断插 入表，region不断增大，当增大到一个阀值的时候，region就会等分会 两个新的region（裂变）；</li><li>当table中的行不断增多，就会有越来越多的region。这样一张完整的表 被保存在多个Regionserver上。</li></ul><p><strong>Memstore 与 storefile</strong></p><ul><li>一个region由多个store组成，一个store对应一个CF（列族）</li><li>store包括位于内存中的memstore和位于磁盘的storefile写操作先写入 memstore，当memstore中的数据达到某个阈值，hregionserver会启动 flashcache进程写入storefile，每次写入形成单独的一个storefile</li><li>当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、 major compaction），在合并过程中会进行版本合并和删除工作 （majar），形成更大的storefile。</li><li>当一个region所有storefile的大小和超过一定阈值后，会把当前的region 分割为两个，并由hmaster分配到相应的regionserver服务器，实现负载均衡。</li><li>客户端检索数据，先在memstore找，找不到再找storefile</li><li>HRegion是HBase中分布式存储和负载均衡的最小单元。最小单元就表 示不同的HRegion可以分布在不同的HRegion server上。</li><li>HRegion由一个或者多个Store组成，每个store保存一个columns family。</li><li>每个Strore又由一个memStore和0至多个StoreFile组成。</li></ul><h1><span id="2-安装搭建hadoop">2. 安装搭建hadoop</span></h1><h2><span id="21-配置说明">2.1 配置说明</span></h2><p>本次集群搭建共三台机器，具体说明下:</p><table><thead><tr><th><strong>主机名</strong></th><th><strong>IP</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>hadoop01</td><td>192.168.154.130</td><td>DataNode、NodeManager、ResourceManager、NameNode</td></tr><tr><td>hadoop02</td><td>192.168.154.131</td><td>DataNode、NodeManager、SecondaryNameNode</td></tr><tr><td>hadoop03</td><td>192.168.154.132</td><td>DataNode、NodeManager</td></tr></tbody></table><h2><span id="22-安装前准备">2.2 安装前准备</span></h2><h3><span id="221-机器配置说明">2.2.1 机器配置说明</span></h3><p>发行版：</p><pre><code class="bash">cat /etc/redhat-release
</code></pre><p><img loading="lazy" src="/../images/image-20240126182118106.png" alt="image-20240126182118106"></p><p>内核版本：</p><pre><code class="bash">uname -r
</code></pre><p><img loading="lazy" src="/../images/image-20240126182259980.png" alt="image-20240126182259980"></p><blockquote><p>注：本集群内所有进程均由hdfs用户启动；要在集群所有服务器都进行操作。</p></blockquote><h3><span id="222-关闭selinux-防火墙">2.2.2 关闭selinux、防火墙</span></h3><p>SELinux（Security-Enhanced Linux）是一个 Linux 内核模块，它为 Linux 系统提供了强制访问控制（MAC）机制。SELinux 最初由美国国家安全局（NSA）开发，并且现在是许多 Linux 发行版（如 Fedora、RHEL、CentOS 等）的一部分。</p><p>在默认的 Linux 安全模型中，用户和程序主要通过文件权限（即，读取、写入和执行权限）来控制对资源的访问。然而，这种模型可能会被恶意程序利用，例如，如果一个程序被设计为以 root 用户身份运行，那么它就可以访问系统上的任何文件。</p><p>SELinux 通过实施更详细和精细的访问控制策略来解决这个问题。例如，即使一个程序以 root 用户身份运行，SELinux 也可以限制它只能访问特定的文件和资源。这种安全模型可以防止或至少减轻某些类型的系统攻击，如缓冲区溢出攻击。</p><p>然而，SELinux 的配置和管理可能会比较复杂，因为它需要详细的安全策略。因此，一些用户可能会选择关闭 SELinux，尽管这可能会降低系统的安全性。</p><blockquote><p>在 Linux 系统中，你可以通过以下步骤来临时或永久关闭 SELinux：</p></blockquote><p><strong>临时关闭 SELinux：</strong></p><p>你可以使用 <code>setenforce</code> 命令来临时关闭 SELinux。这个命令会立即生效，但在系统重启后，SELinux 会再次被启用。在终端中输入以下命令：</p><pre><code class="bash">sudo setenforce 0
</code></pre><p>这里，<code>0</code> 表示关闭 SELinux，<code>1</code> 表示开启 SELinux。</p><p><strong>永久关闭 SELinux：</strong></p><p>如果你想要永久关闭 SELinux，你需要编辑 <code>/etc/selinux/config</code> 文件。在这个文件中，你会找到 <code>SELINUX</code> 这一行，你可以将其值设置为 <code>disabled</code> 来关闭 SELinux。以下是具体的步骤：</p><ol><li>打开 <code>/etc/selinux/config</code> 文件：</li></ol><pre><code class="bash">sudo nano /etc/selinux/config
</code></pre><ol start="2"><li>找到 <code>SELINUX</code> 这一行，将其值改为 <code>disabled</code>：</li></ol><pre><code class="bash">SELINUX=disabled
</code></pre><p><img loading="lazy" src="/../images/image-20240126183004320.png" alt="image-20240126183004320"></p><ol start="3"><li>保存并关闭文件。</li><li>重启你的系统以使更改生效：</li></ol><pre><code class="bash">sudo reboot
</code></pre><pre><code class="bash">sestatus
</code></pre><p><img loading="lazy" src="/../images/image-20240126182832390.png" alt="image-20240126182832390"></p><p><strong>关闭防火墙</strong></p><p>在 CentOS 系统中，你可以使用 <code>firewall-cmd</code> 命令来管理防火墙。以下是关闭防火墙的步骤：</p><blockquote><p>临时关闭防火墙：</p></blockquote><p>你可以使用以下命令来临时关闭防火墙，这个命令会立即生效，但在系统重启后，防火墙会再次被启用：</p><pre><code class="bash">sudo systemctl stop firewalld
</code></pre><blockquote><p>永久关闭防火墙：</p></blockquote><p>如果你想要永久关闭防火墙，你需要使用 <code>systemctl</code> 命令来禁用 <code>firewalld</code> 服务。以下是具体的步骤：</p><ol><li>使用以下命令停止 <code>firewalld</code> 服务：</li></ol><pre><code class="bash">sudo systemctl stop firewalld
</code></pre><ol start="2"><li>使用以下命令禁用 <code>firewalld</code> 服务：</li></ol><pre><code class="bash">sudo systemctl disable firewalld
</code></pre><p>这样，即使在系统重启后，防火墙也不会再次启动。</p><blockquote><p>查看防火墙是否关闭</p></blockquote><pre><code class="bash">sudo systemctl status firewalld
</code></pre><p><img loading="lazy" src="/../images/image-20240126183648528.png" alt="image-20240126183648528"></p><blockquote><p>查看重启后还会不会自动启动</p></blockquote><pre><code class="bash">sudo systemctl is-enabled firewalld
</code></pre><p>如果这个命令返回 “disabled”，那么防火墙在系统重启后不会自动启动。如果它返回 “enabled”，那么防火墙在系统重启后会自动启动。</p><h3><span id="223-准备用户">2.2.3 准备用户</span></h3><blockquote><p>因为Hadoop启动时默认以非root启动，以root启动会有各种报错，难以解决，所以我们需要创建一个普通用户</p></blockquote><p><strong>创建用户</strong></p><pre><code class="bash">sudo useradd hdfs
</code></pre><p><strong>设置密码</strong></p><pre><code class="bash">sudo passwd hdfs
</code></pre><p><strong>加入sudoers</strong></p><p>以便可以使用sudo命令</p><pre><code class="bash">sudo visudo
</code></pre><p>找到类似于以下的行：</p><pre><code>root    ALL=(ALL:ALL) ALL
</code></pre><p>在这一行下面，添加一个新的行，将 “hdfs” 替换为你想要添加的用户名：</p><pre><code>hdfs    ALL=(ALL:ALL) ALL
</code></pre><p><img loading="lazy" src="/../images/image-20240126185145185.png" alt="image-20240126185145185"></p><h3><span id="224-修改hosts文件域名解析">2.2.4 修改hosts文件，域名解析</span></h3><pre><code class="bash">sudo vim /etc/hosts
</code></pre><p>添加以下行：</p><pre><code>192.168.154.130 hadoop01
192.168.154.131 hadoop02
192.168.154.132 hadoop03
</code></pre><p>（每个人不同）</p><p><img loading="lazy" src="/../images/image-20240126185445948.png" alt="image-20240126185445948"></p><h3><span id="225-同步时间">2.2.5 同步时间</span></h3><pre><code class="bash">sudo yum -y install ntpdate
sudo ntpdate cn.pool.ntp.org
</code></pre><h3><span id="226-ssh互信配置">2.2.6 ssh互信配置</span></h3><blockquote><p>注：要在集群所有服务器都进行操作</p></blockquote><p>（1）生成密钥对，一直回车即可</p><pre><code class="bash">ssh-keygen
</code></pre><p>默认RSA，创建ed25519也行，但是RSA这里复制公钥方便一丢丢。</p><p>（2）保证每台服务器各自都有对方的公钥(包括自己)</p><pre><code class="bash">ssh-copy-id hdfs@hadoop01
ssh-copy-id hdfs@hadoop02
ssh-copy-id hdfs@hadoop03
</code></pre><p>（3）验证无秘钥认证登录</p><pre><code class="bash">ssh hdfs@hadoop01
ssh hdfs@hadoop02
ssh hdfs@hadoop03
</code></pre><h2><span id="23-配置jdk">2.3 配置jdk</span></h2><p>从CentOS的yum源安装或者自己下载解压安装都可以</p><blockquote><p><strong>yum安装</strong></p></blockquote><pre><code class="bash">sudo yum update
sudo yum install java-1.8.0-openjdk-devel
</code></pre><p>查看安装目录：</p><pre><code class="bash">readlink -f $(which java)
</code></pre><p><img loading="lazy" src="/../images/image-20240126200311094.png" alt="image-20240126200311094"></p><p>设置JAVA_HOME：</p><pre><code class="bash">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.392.b08-2.el7_9.x86_64
</code></pre><p>验证JAVA_HOME：</p><pre><code class="bash">echo $JAVA_HOME
</code></pre><p><img loading="lazy" src="/../images/image-20240126200428768.png" alt="image-20240126200428768"></p><p>查看版本：</p><pre><code class="bash">java -version
</code></pre><p><img loading="lazy" src="/../images/image-20240126191803042.png" alt="image-20240126191803042"></p><blockquote><p><strong>下载解压安装</strong></p></blockquote><p>自行下载或者上传一个jdk包，解压：</p><pre><code class="bash">tar -xvf jdk-8u201-linux-x64.tar.gz -C /usr/local
</code></pre><p>授权：</p><pre><code class="bash">chown hdfs.hdfs -R /usr/local/jdk1.8.0_201/
</code></pre><p>软连接：</p><pre><code class="bash">ln -s /usr/local/jdk1.8.0_201/ /usr/local/jdk
</code></pre><p>配置环境变量：</p><pre><code class="bash">sudo vim /etc/profile.d/jdk.sh
</code></pre><p>添加以下行：</p><pre><code>export JAVA_HOME=/usr/local/jdk
PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
</code></pre><p>使生效：</p><pre><code class="bash">source /etc/profile.d/jdk.sh
</code></pre><p>验证：</p><pre><code class="bash">java -version
</code></pre><pre><code>java version &quot;1.8.0_201&quot;
Java(TM) SE Runtime Environment (build 1.8.0_201-b09)
Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)
</code></pre><h2><span id="24-安装hadoop">2.4 安装Hadoop</span></h2><p>CentOS自带的yum不含Hadoop的资源，所以我们要手动下载：</p><p><strong>下载：</strong></p><pre><code class="bash">wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6-src.tar.gz
</code></pre><p><strong>解压到~下：</strong></p><pre><code class="bash">tar -xvf hadoop-3.3.6.tar.gz -C ~/
</code></pre><p><strong>授权：</strong></p><pre><code class="bash">chown hdfs.hdfs -R ~/hadoop-3.3.6
</code></pre><blockquote><p>这只是一台的配置，等会配置完直接通过scp复制到其他节点</p></blockquote><h1><span id="3-配置启动hadoop">3. 配置启动hadoop</span></h1><h2><span id="31-hadoop-envsh-配置hadoop环境变量">3.1 hadoop-env.sh 配置hadoop环境变量</span></h2><pre><code class="bash">cd ~/hadoop-3.3.6/etc/hadoop/
vim hadoop-env.sh
</code></pre><p>添加如下行：</p><pre><code>export JAVA_HOME=/usr/local/jdk
export HADOOP_HOME=~/hadoop-3.3.6
export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop
</code></pre><p>如果之前通过yum安装的jdk，你应该查找jdk安装目录：</p><pre><code class="bash">readlink -f $(which java)
</code></pre><p><img loading="lazy" src="/../images/image-20240126195443067.png" alt="image-20240126195443067"></p><blockquote><p>那么JAVA_HOME就为&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.392.b08-2.el7_9.x86_64（安装目录）</p></blockquote><h2><span id="32-core-sitexml-配置hdfs">3.2 core-site.xml 配置HDFS</span></h2><pre><code class="bash">vim core-site.xml
</code></pre><pre><code>&lt;configuration&gt;
    &lt;!-- 指定HDFS默认（namenode）的通信地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定hadoop运行时产生文件的存储路径 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/data/hadoop/tmp&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h2><span id="33-hdfs-sitexml-配置namenode">3.3 hdfs-site.xml 配置namenode</span></h2><pre><code class="bash">vim hdfs-site.xml
</code></pre><pre><code>&lt;configuration&gt;
    &lt;!-- 设置namenode的http通讯地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
        &lt;value&gt;hadoop01:50070&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;!-- 设置secondarynamenode的http通讯地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;hadoop02:50090&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;!-- 设置namenode存放的路径 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;/data/hadoop/name&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;!-- 设置hdfs副本数量 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 设置datanode存放的路径 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;/data/hadoop/datanode&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;property&gt;
        &lt;name&gt;dfs.permissions&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><pre><code class="bash">sudo mkdir /data/hadoop/name -p
sudo mkdir /data/hadoop/datanode -p
</code></pre><h2><span id="34-mapred-sitexml-配置框架">3.4 mapred-site.xml 配置框架</span></h2><pre><code class="bash">vim mapred-site.xml
</code></pre><pre><code>&lt;configuration&gt;
    &lt;!-- 通知框架MR使用YARN --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;
        &lt;value&gt;
        /usr/local/hadoop/etc/hadoop,
        /usr/local/hadoop/share/hadoop/common/*,
        /usr/local/hadoop/share/hadoop/common/lib/*,
        /usr/local/hadoop/share/hadoop/hdfs/*,
        /usr/local/hadoop/share/hadoop/hdfs/lib/*,
        /usr/local/hadoop/share/hadoop/mapreduce/*,
        /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
        /usr/local/hadoop/share/hadoop/yarn/*,
        /usr/local/hadoop/share/hadoop/yarn/lib/*
        &lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h2><span id="35-yarn-sitexml-配置resourcemanager">3.5 yarn-site.xml 配置resourcemanager</span></h2><pre><code class="bash">vim yarn-site.xml
</code></pre><pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;hadoop01&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;property&gt;
        &lt;description&gt;The http address of the RM web application.&lt;/description&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
        &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;property&gt;
        &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt;
        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
        &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;property&gt;
        &lt;description&gt;The address of the scheduler interface.&lt;/description&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
        &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
        &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;property&gt;
        &lt;description&gt;The address of the RM admin interface.&lt;/description&gt;
        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
        &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h2><span id="36-配置masters-amp-slaves">3.6 配置masters &amp; slaves</span></h2><pre><code class="bash">echo &#39;hadoop01&#39; &gt;&gt; ~/hadoop-3.3.6/etc/hadoop/masters
echo &#39;hadoop02 hadoop03&#39; &gt;&gt; ~/hadoop-3.3.6/etc/hadoop/slaves
</code></pre><h2><span id="37-启动前准备">3.7 启动前准备</span></h2><h3><span id="371-准备启动脚本">3.7.1 准备启动脚本</span></h3><p>启动脚本文件全部位于 ~&#x2F;hadoop-3.3.6&#x2F;sbin&#x2F; 文件夹下：</p><p>（1）修改 start-dfs.sh 和 stop-dfs.sh 文件添加：</p><pre><code>HDFS_DATANODE_USER=hdfs
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=hdfs
HDFS_SECONDARYNAMENODE_USER=hdfs
</code></pre><p>（2）修改start-yarn.sh 和 stop-yarn.sh文件添加：</p><pre><code>YARN_RESOURCEMANAGER_USER=hdfs
HADOOP_SECURE_DN_USER=hdfs
YARN_NODEMANAGER_USER=hdfs
</code></pre><h3><span id="372-授权">3.7.2 授权</span></h3><pre><code class="bash">sudo chown -R hdfs.hdfs ~/hadoop-3.3.6/
sudo chown -R hdfs.hdfs /data/hadoop/
</code></pre><h3><span id="373-配置hadoop命令环境变量">3.7.3 配置hadoop命令环境变量</span></h3><pre><code class="bash">sudo vim /etc/profile.d/hadoop.sh
</code></pre><p>添加如下：</p><pre><code>export HADOOP_HOME=~/hadoop-3.3.6
PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
</code></pre><h3><span id="374-集群初始化">3.7.4 集群初始化</span></h3><blockquote><p>我们在hadoop01上修改了hadoop-3.3.6下的很多文件，现在要同步到hadoop02和hadoop03</p></blockquote><p>使用scp命令：</p><pre><code class="bash">scp -r ~/hadoop-3.3.6 hadoop02:~/
scp -r ~/hadoop-3.3.6 hadoop03:~/
</code></pre><h2><span id="38-启动hadoop集群">3.8 启动Hadoop集群</span></h2><h3><span id="381-第一次启动前需要格式化集群所有服务器都需要">3.8.1 第一次启动前需要格式化，集群所有服务器都需要</span></h3><pre><code class="bash">hdfs namenode -format
</code></pre><h3><span id="382-启动并验证集群">3.8.2 启动并验证集群</span></h3><h4><span id="1启动namenode-datanode">（1）启动namenode、datanode</span></h4><p>三台都需要：</p><pre><code class="bash">start-dfs.sh
</code></pre><p>查看进程：</p><pre><code class="bash">jps
</code></pre><p><img loading="lazy" src="/../images/image-20240126204444006.png" alt="image-20240126204444006"></p><p><img loading="lazy" src="/../images/image-20240126204542442.png" alt="image-20240126204542442"></p><p><img loading="lazy" src="/../images/image-20240126204657107.png" alt="image-20240126204657107"></p><p>这里的截图也包含了后面的hbase进程</p><h4><span id="2启动yarn">（2）启动YARN</span></h4><p>三台都需要：</p><pre><code class="bash">start-yarn.sh
</code></pre><p>查看进程：</p><pre><code class="bash">jps
</code></pre><p>同上，一次截完了</p><h3><span id="39-集群启动成功">3.9 集群启动成功</span></h3><p>（1）网页访问：<a target="_blank" rel="noopener" href="http://hadoop01:8088/">http://hadoop01:8088</a></p><p>该页面为ResourceManager 管理界面，在上面可以看到集群中的三台Active Nodes：</p><p><img loading="lazy" src="/../images/image-20240126205252646.png" alt="image-20240126205252646"></p><p>（2）网页访问：<a target="_blank" rel="noopener" href="http://hadoop01:50070/dfshealth.html#tab-datanode">http://hadoop01:50070/dfshealth.html#tab-datanode</a></p><p>该页面为NameNode管理页面：</p><p><img loading="lazy" src="/../images/image-20240126205344804.png" alt="image-20240126205344804"></p><blockquote><p><strong>到此hadoop集群已经搭建完毕！！！</strong></p></blockquote><h1><span id="4-安装配置hbase">4. 安装配置Hbase</span></h1><h2><span id="41-安装hbase">4.1 安装HBase</span></h2><p>下载：</p><pre><code class="bash">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/2.5.7/hbase-2.5.7-bin.tar.gz
</code></pre><p>解压：</p><pre><code class="bash">tar -xvf hbase-2.5.7-bin.tar.gz -C ~/hbase-2.5.7
</code></pre><p>授权：</p><pre><code class="bash">sudo chown -R hdfs.hdfs ~/hbase-2.5.7/
</code></pre><h2><span id="42-配置hbase">4.2 配置HBase</span></h2><h3><span id="421-hbase-envsh-配置hbase环境变量">4.2.1 hbase-env.sh 配置hbase环境变量</span></h3><pre><code class="bash">cd ~/hbase-2.5.7/conf/
vim vim hbase-env.sh
</code></pre><pre><code class="bash">export JAVA_HOME=/usr/local/jdk
export HBASE_CLASSPATH=~/hbase-2.5.7/conf
</code></pre><h3><span id="422-hbase-sitexml-配置hbase">4.2.2 hbase-site.xml 配置hbase</span></h3><pre><code>vim hbase-site.xml
</code></pre><pre><code>&lt;configuration&gt;
&lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;!-- hbase存放数据目录 --&gt;
    &lt;value&gt;hdfs://hadoop01:9000/hbase/hbase_db&lt;/value&gt;
    &lt;!-- 端口要和Hadoop的fs.defaultFS端口一致--&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;!-- 是否分布式部署 --&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;!-- zookooper 服务启动的节点，只能为奇数个 --&gt;
    &lt;value&gt;hadoop01,hadoop02,hadoop03&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;!--zookooper配置、日志等的存储位置，必须为以存在 --&gt;
    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
    &lt;value&gt;/data/hbase/zookeeper&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;!--hbase master --&gt;
    &lt;name&gt;hbase.master&lt;/name&gt;
    &lt;value&gt;hadoop01&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;!--hbase web 端口 --&gt;
    &lt;name&gt;hbase.master.info.port&lt;/name&gt;
    &lt;value&gt;16666&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>注：zookeeper有这样一个特性：</p><ul><li>集群中只要有过半的机器是正常工作的，那么整个集群对外就是可用的。</li><li>也就是说如果有2个zookeeper，那么只要有1个死了zookeeper就不能用了，因为1没有过半，所以2个zookeeper的死亡容忍度为0；</li><li>同理，要是有3个zookeeper，一个死了，还剩下2个正常的，过半了，所以3个zookeeper的容忍度为1；</li><li>再多列举几个：2-&gt;0 ; 3-&gt;1 ; 4-&gt;1 ; 5-&gt;2 ; 6-&gt;2 会发现一个规律，2n和2n-1的容忍度是一样的，都是n-1，所以为了更加高效，何必增加那一个不必要的zookeeper</li></ul><h3><span id="423-指定集群节点">4.2.3 指定集群节点</span></h3><pre><code class="bash">vim regionservers
</code></pre><p>添加如下：</p><pre><code>hadoop01
hadoop02
hadoop03
</code></pre><h1><span id="5-启动hbase集群">5. 启动Hbase集群</span></h1><h2><span id="51-配置hbase命令环境变量">5.1 配置hbase命令环境变量</span></h2><pre><code class="bash">sudo vim /etc/profile.d/hbase.sh
</code></pre><p>添加如下：</p><pre><code>export HBASE_HOME=~/hbase-2.5.7
PATH=$HBASE_HOME/bin:$PATH
</code></pre><h2><span id="52-启动前准备">5.2 启动前准备</span></h2><pre><code class="bash">sudo mkdir -p /data/hbase/zookeeper
vim /data/hbase/rsync.sh
</code></pre><p>添加以下内容：</p><pre><code class="bash">for i in hadoop02 hadoop03
    do
         sudo rsync -a /data/hbase $i:/data/
         sudo scp -p /etc/profile.d/hbase.sh $i:/etc/profile.d/
done
 
#复制hbase配置到其他机器
for i in hadoop02 hadoop03
    do
         sudo rsync -a  ~/hbase-2.5.6 $i:~/hbase-2.5.6
done
</code></pre><p>授权：</p><pre><code class="bash">sudo chown -R hdfs.hdfs /data/hbase
</code></pre><p>启动复制脚本：</p><pre><code class="bash">./data/hbase/rsync.sh
</code></pre><h2><span id="53-启动hbase">5.3 启动hbase</span></h2><p>注：只需在hadoop01服务器上操作即可。</p><p>（1）启动</p><pre><code class="bash">start-hbase.sh
</code></pre><p>（2）验证</p><pre><code class="bash">jps
</code></pre><p><img loading="lazy" src="/../images/image-20240126211709277.png" alt="image-20240126211709277"></p><p>同上Hadoop</p><h2><span id="54-页面查看hbase状态">5.4 页面查看hbase状态</span></h2><p>网页访问<a target="_blank" rel="noopener" href="http://hadoop01:16666/">http://hadoop01:16666</a></p><p><img loading="lazy" src="/../images/image-20240126210922766.png" alt="image-20240126210922766"></p><h1><span id="6-后续及其总结">6. 后续及其总结</span></h1><p>安装之后可以进行后面的操作，如建表，修改HBase表，等等。</p><p>进行各种环境变量配置时一定要细心，每进行到一个阶段都推荐使用快照保存一下。</p><p>虽然配环境真的头大，但是也复习了很多Linux基础命令。</p></div><div id="comment"><div id="twikoo-container"></div></div></div><footer id="footer"><div id="footer-wrap"><div>&copy; 2023 - 2024 Tianzhen <span id="footer-icon"><i class="fa-solid fa-font-awesome fa-fw"></i> </span>&commat;Tianzhen</div><div>Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp; <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a></div><div><a href="https://icp.gov.moe/?keyword=20236514" target="_blank">萌ICP备20236514号</a> <a target="_blank" rel="noopener" href="https://beian.miit.gov.cn">豫ICP备2023040339号</a></div></div><div><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("11/07/2023 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="本站已运行 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}setInterval("createtime()",250)</script></div></footer></div><transition name="fade"><div id="preview" ref="preview" v-show="previewShow"><img id="preview-content" ref="previewContent"></div></transition></div><script src="/api/js/main.js"></script><script>twikoo.init({el:"#twikoo-container",envId:"https://twikoo.lt514.com",region:"",path:location.pathname,lang:"zh"})</script><p style="text-align:center;margin:0" id="saintwei"></p><script>var saintwei=function(r){var i="気：",n=["现在开始天晴了","天空比大海还要深，是个未知的世界","天气因你逆转，世界因你天晴","能遇见你真是太好了","不管晴天还是雨天，我只是想和你相遇","我只是想再一次的见到她啊","是你让我找到了存在的意义","无论你在哪里，我一定拼尽全力去见你","拜托了，我们就这样一直在一起","只是天空的样子，就能改变人们的心情","天空上是另一个世界，自古如此","我从来不知道，渴望蓝天的人居然有那么多","天气真的是很不可思议，光只是天空的模样就让人感动不已","这是一个只有我和她知道，关于这世界的秘密","100%的晴天女孩","在充满暴风雨的世界，一起勇敢地爱下去","那年夏天，在那个天空之上的我们，把这个世界的样貌，彻底的改变了","天空比大海还要深，是个未知的世界","重要的人，想见的人，无论晴雨，不管多远，都一定要去见你","晴天里有阳光，阳光总是充满温馨，相信有这么多朋友的厚爱和鼓励，晴天会永远阳光灿烂","天晴得像一张蓝纸，几片薄薄的白云，像被阳光晒化了似的，随风缓缓浮游着","天空澄碧，纤云不染，远山含黛，和风送暖","浅蓝色的天幕，像一幅洁净的丝绒，镶着黄色的金边","一场飘洒的雨后，阳光带着清醒的空气飞来，试问是哪位仙子的生日，阳光如此美丽","晴天的午后，夏日的阳光如水般音符一样灿烂的流动，湿澈了不同的妩媚的忧伤","天那么蓝，连一丝浮絮都没有，像被过滤了一切杂色，瑰丽地熠熠发光","神明啊!求你!求你!求你!让我再见她一次","比起晴空，我更需要阳菜，天气什么的，就这样疯狂下去也可以"].map(function(t){return t}),l=["rgb(110,64,170)","rgb(150,61,179)","rgb(191,60,175)","rgb(228,65,157)","rgb(254,75,131)","rgb(255,94,99)","rgb(255,120,71)","rgb(251,150,51)","rgb(226,183,47)","rgb(198,214,60)","rgb(175,240,91)","rgb(127,246,88)","rgb(82,246,103)","rgb(48,239,130)","rgb(29,223,163)","rgb(26,199,194)","rgb(35,171,216)","rgb(54,140,225)","rgb(76,110,219)","rgb(96,84,200)"],a={text:"",prefixP:-5,skillI:0,skillP:0,direction:"forward",delay:2,step:1};!function t(){var e=n[a.skillI];a.step?a.step--:(a.step=1,a.prefixP<i.length?(0<=a.prefixP&&(a.text+=i[a.prefixP]),a.prefixP++):"forward"===a.direction?a.skillP<e.length?(a.text+=e[a.skillP],a.skillP++):a.delay?a.delay--:(a.direction="backward",a.delay=2):0<a.skillP?(a.text=a.text.slice(0,-1),a.skillP--):(a.skillI=(a.skillI+1)%n.length,a.direction="forward")),r.textContent=a.text,r.appendChild(function(t){for(var e=document.createDocumentFragment(),r=0;r<t;r++){var i=document.createElement("span");i.textContent=String.fromCharCode(94*Math.random()+33),i.style.color=l[Math.floor(Math.random()*l.length)],e.appendChild(i)}return e}(a.prefixP<i.length?Math.min(5,5+a.prefixP):Math.min(5,e.length-a.skillP))),setTimeout(t,75)}()};saintwei(document.getElementById("saintwei"))</script></body></html>